{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_snake\n",
    "import random\n",
    "import numpy as np\n",
    "from stable_baselines import PPO2\n",
    "from gym.envs.registration import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(env, model):\n",
    "    reward = 0\n",
    "    length = 0\n",
    "\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, step_reward, done, _ = env.step(action)\n",
    "        length += 1\n",
    "        reward += step_reward\n",
    "    return reward, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_path, episodes=1000, kwargs={}):\n",
    "    # Create env and load model\n",
    "    registered_name = f'Snake-inference_{random.randint(0, 1000000)}-v0'\n",
    "    register(id=registered_name,\n",
    "             entry_point='gym_snake.envs:SnakeEnv',\n",
    "             kwargs=kwargs)\n",
    "    env = gym.make(registered_name)\n",
    "    model = PPO2.load(model_path)\n",
    "    \n",
    "    # Perform inference\n",
    "    rewards = []\n",
    "    lengths = []\n",
    "    for episode in range(episodes):\n",
    "        print(f'Episode {episode+1}/{episodes}')\n",
    "        reward, length = inference(env, model)\n",
    "        rewards.append(reward)\n",
    "        lengths.append(length)\n",
    "    return rewards, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "Episode 1/10\n",
      "Episode 2/10\n",
      "Episode 3/10\n",
      "Episode 4/10\n",
      "Episode 5/10\n",
      "Episode 6/10\n",
      "Episode 7/10\n",
      "Episode 8/10\n",
      "Episode 9/10\n",
      "Episode 10/10\n",
      "\n",
      "Min reward: 106.09999999999982\n",
      "Max reward: 265.39999999999975\n",
      "Avg reward: 212.0399999999996\n",
      "\n",
      "Min length: 163\n",
      "Max length: 1224\n",
      "Avg length: 598.5\n"
     ]
    }
   ],
   "source": [
    "rewards, lengths = test_model(\n",
    "    model_path='/home/oskar/kth/kex/simple-env/experiments/models/empty_map_4e_1M.pkl',\n",
    "    #model_path='/home/oskar/kth/kex/simple-env/experiments/models/increasing_complexity_4e_1M.pkl',\n",
    "    #model_path='/home/oskar/kth/kex/simple-env/experiments/models/no_increased_complexity_4e_1M.pkl',\n",
    "    episodes=10,\n",
    "    kwargs = {\n",
    "        'sticky': False,\n",
    "        #'obstacle_rate': 0.08,\n",
    "        'level': 'empty'\n",
    "    })\n",
    "\n",
    "print('\\nMin reward:', min(rewards))\n",
    "print('Max reward:', max(rewards))\n",
    "print('Avg reward:', np.average(rewards))\n",
    "\n",
    "print('\\nMin length:', min(lengths))\n",
    "print('Max length:', max(lengths))\n",
    "print('Avg length:', np.average(lengths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
